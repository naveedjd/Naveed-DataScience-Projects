{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC Parking Ticket - EDA - Case Study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objectives\n",
    ">- The objective of this case study is to do exploratory data analysis using pyspark and drawing inference from the data, in big data clustered distributed environment. Also one of the main objective is to gain familiarity with how data analysis works in pyspark.<br><br>\n",
    ">- Our Analysis is focussed on performing exploratory data analysis to understand the parking violation dataset. We will compare metrics/phenomenon related to Parking Tickets for the fiscal year 2017. The Analysis will be performed using Pyspark running in corestack with data in Hadoop HDFS Cluster.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Data Description\n",
    ">- The data for this case study has been placed in HDFS at the following path: `'/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv'`<br>\n",
    "\n",
    "> The Data Dictionary for this dataset is as follows: (Field Name (Type) --Description  )<br>\n",
    "1.  `Summons Number     - (long)`     : Unique Identifier Of Summons (Primary Key)  \n",
    "2.  `Plate ID           - (string)`   : Registered Plate Id\n",
    "3.  `Registration State - (string)`   : State Of Plate Registration\n",
    "4.  `Issue Date         - (timestamp)`: Issue Date \n",
    "5.  `Violation Code     - (integer)`  : Type Of Violation\n",
    "6.  `Vehicle Body Type  - (string)`   : Vehicle Body Type Written On Summons\n",
    "7.  `Vehicle Make       - (string)`   : Make Of Car Written On Summons\n",
    "8.  `Violation Precinct - (integer)`  : Percinct Of Violation\n",
    "9.  `Issuer Precinct    - (integer)`  : Precinct Of Issuance\n",
    "10. `Violation Time     - (string)`   : Time Violation Occurred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions<br>\n",
    ">1. The dataset under folder `/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv` for this case study has tickets issued from year 1972. It is assumed that for this case study, we are considering only 2017 year data, the rest of the year data has been filtered and been removed.\n",
    "\n",
    ">2. The attribute names in the dataset contain white spaces and special characters. To facilitate ease of analysis we have replaced the white spaces with “_” and removed special characters.\n",
    "\n",
    ">3. The date and time formats are not in a standard format therefore we have conducted data manipulation to extract the required information as per the requirement.\n",
    " \n",
    ">4. We have used the details from NYC Department of finance for Violation of code, fines details for The Ticket Fine revenue estimation with the help of the following Source:  http://www1.nyc.gov/site/finance/vehicles/services-violation-codes.page\n",
    "\n",
    ">5. The Seasonality vs. Ticket Frequency analysis was performed by creating buckets for the season with reference to the ticket’s Issue_Date [i.e, Issue_Month]. \n",
    "    - The seasons were defined with an assumption as as follows:<br> \n",
    "         a. Spring runs from March 1 to May 31; <br>\n",
    "         b. Summer runs from June 1 to August 31; <br>\n",
    "         c. Fall (autumn) runs from September 1 to November 30; and,<br>\n",
    "         d. Winter runs from December 1 to February 28.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1:  Data Quality Verification and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Initialise the Spark Session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Application Spark Session.\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"NYC Parking Ticket Application\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Import the NYC Parking 2017 dataset into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_parking_tkt_2017 = spark.read.format(\"csv\") \\\n",
    "                        .option(\"header\",\"true\") \\\n",
    "                        .option(\"inferschema\",\"true\") \\\n",
    "                        .load('/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv') \\\n",
    "                        .coalesce(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Summons Number: bigint, Plate ID: string, Registration State: string, Issue Date: timestamp, Violation Code: int, Vehicle Body Type: string, Vehicle Make: string, Violation Precinct: int, Issuer Precinct: int, Violation Time: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cache dataframe for better performance\n",
    "nyc_parking_tkt_2017.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Verify Dimensions, Schema and Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (10803028, 10)\n"
     ]
    }
   ],
   "source": [
    "# print number of rows & columns in the dataframe.\n",
    "print(\"Shape: \", (nyc_parking_tkt_2017.count(),len(nyc_parking_tkt_2017.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Summons Number: long (nullable = true)\n",
      " |-- Plate ID: string (nullable = true)\n",
      " |-- Registration State: string (nullable = true)\n",
      " |-- Issue Date: timestamp (nullable = true)\n",
      " |-- Violation Code: integer (nullable = true)\n",
      " |-- Vehicle Body Type: string (nullable = true)\n",
      " |-- Vehicle Make: string (nullable = true)\n",
      " |-- Violation Precinct: integer (nullable = true)\n",
      " |-- Issuer Precinct: integer (nullable = true)\n",
      " |-- Violation Time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the schema of the dataframe.\n",
    "nyc_parking_tkt_2017.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    5092469481| GZH7067|                NY|2016-07-10 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|         0143A|\n",
      "|    5092451658| GZH7067|                NY|2016-07-08 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|         0400P|\n",
      "|    4006265037| FZX9232|                NY|2016-08-23 00:00:00|             5|             SUBN|        FORD|                 0|              0|         0233P|\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|\n",
      "|    7868300310| 37033JV|                NY|2016-11-21 00:00:00|            69|             DELV|       INTER|                13|             13|         0555P|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print top 5 rows.\n",
    "nyc_parking_tkt_2017.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations***<br>\n",
    " - The comma delimeted csv file `NYC Parking violation data for year 2017` is imported in to a dataframe.\n",
    " - There are `10,803,028` rows and `10` columns in the dataframe.\n",
    " - It is observed that there are issues in the column names.\n",
    "     - There are spaces before and after the column names.\n",
    "     - The column names have spaces in between the words which is NOT conformable for SQL queries.<br>\n",
    "     \n",
    "***Inference***<br>\n",
    " - The column names should be fixed before creating view Table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Fix Column Names of DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Summons_Number',\n",
       " 'Plate_ID',\n",
       " 'Registration_State',\n",
       " 'Issue_Date',\n",
       " 'Violation_Code',\n",
       " 'Vehicle_Body_Type',\n",
       " 'Vehicle_Make',\n",
       " 'Violation_Precinct',\n",
       " 'Issuer_Precinct',\n",
       " 'Violation_Time']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "#from pyspark.sql.functions import col\n",
    "\n",
    "# Trim the column Names and replaces spaces between words in the column Names with underscore (_)\n",
    "for col_name in nyc_parking_tkt_2017.columns:\n",
    "    nyc_parking_tkt_2017 = nyc_parking_tkt_2017.withColumnRenamed(col_name,col_name.replace(\" \", \"_\").strip())\n",
    "\n",
    "# Check the column Names.\n",
    "nyc_parking_tkt_2017.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Observations***<br>\n",
    " - The column names in the dataframe has white spaces and also leading and trailing whitespaces\n",
    " - The column Names are trimmed and words in the column name delimited with underscore (_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+--------------+\n",
      "|Summons_Number|         Issue_Date|Violation_Time|\n",
      "+--------------+-------------------+--------------+\n",
      "|    5092469481|2016-07-10 00:00:00|         0143A|\n",
      "|    5092451658|2016-07-08 00:00:00|         0400P|\n",
      "|    4006265037|2016-08-23 00:00:00|         0233P|\n",
      "|    8478629828|2017-06-14 00:00:00|         1120A|\n",
      "|    7868300310|2016-11-21 00:00:00|         0555P|\n",
      "|    5096917368|2017-06-13 00:00:00|         0852P|\n",
      "|    1413609545|2016-08-03 00:00:00|         0215A|\n",
      "|    4628525523|2016-12-21 00:00:00|         0758A|\n",
      "|    4627113330|2016-11-21 00:00:00|         1005A|\n",
      "|    4006478550|2016-10-05 00:00:00|         0845A|\n",
      "+--------------+-------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_parking_tkt_2017.select('Summons_Number','Issue_Date','Violation_Time').show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Duplicate Rows based on same Summons Numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (10803028, 10)\n"
     ]
    }
   ],
   "source": [
    "# Drop any duplicate rows which is having the same Summons_Number.\n",
    "nyc_parking_tkt_2017 = nyc_parking_tkt_2017.dropDuplicates(['Summons_Number'])\n",
    "\n",
    "# Verify Nodup dataframe.\n",
    "print(\"Shape: \",(nyc_parking_tkt_2017.count(),len(nyc_parking_tkt_2017.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Observations***<br>\n",
    " - There are no duplicates in the data frame having duplicate summons Number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Create TemporaryTableView for the Dataframe for SQL Queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_parking_tkt_2017.createOrReplaceTempView(\"tbl_nyctkt_2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Observations***<br>\n",
    "> - A new Temporary View Table `tbl_nyctkt_2017` is created for analysis using SQL Queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Verify Nulls in the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons_Number|Plate_ID|Registration_State|Issue_Date|Violation_Code|Vehicle_Body_Type|Vehicle_Make|Violation_Precinct|Issuer_Precinct|Violation_Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|             0|       0|                 0|         0|             0|                0|           0|                 0|              0|             0|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify for NULL values in the data frame using functions.\n",
    "nyc_parking_tkt_2017.select([count(when(col(c).isNull(), c)).alias(c) \\\n",
    "                                   for c in nyc_parking_tkt_2017.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+------------+--------+-----------+\n",
      "|pid_nulls|rstate_nulls|idate_nulls|vbtype_nulls|vm_nulls|vtime_nulls|\n",
      "+---------+------------+-----------+------------+--------+-----------+\n",
      "|     null|        null|       null|        null|    null|       null|\n",
      "+---------+------------+-----------+------------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_1 = \"SELECT \\\n",
    "             SUM(CASE WHEN Plate_ID IS NULL THEN 1 ELSE 0 END)               AS pid_nulls,\\\n",
    "             SUM(CASE WHEN Registration_State IS NULL THEN 1 ELSE 0 END)     AS rstate_nulls,\\\n",
    "             SUM(CASE WHEN Issue_Date IS NULL THEN 1 ELSE 0 END)             AS idate_nulls,\\\n",
    "             SUM(CASE WHEN Vehicle_Body_Type IS NULL THEN 1 ELSE 0 END)      AS vbtype_nulls,\\\n",
    "             SUM(CASE WHEN Vehicle_Make IS NULL THEN 1 ELSE 0 END)           AS vm_nulls,\\\n",
    "             SUM(CASE WHEN Violation_Time IS NULL THEN 1 ELSE 0 END)         AS vtime_nulls\\\n",
    "         FROM \\\n",
    "             tbl_nyctkt_2017 \\\n",
    "         WHERE \\\n",
    "            (Plate_ID IS NULL            OR \\\n",
    "             Registration_State IS NULL  OR \\\n",
    "             Issue_Date IS NULL          OR \\\n",
    "             Vehicle_Body_Type IS NULL   OR \\\n",
    "             Vehicle_Make IS NULL        OR \\\n",
    "             Violation_Time IS NULL) \" \n",
    "\n",
    "spark.sql(sql_1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Observations***<br>\n",
    " - There are no records with nulls for `Plate_ID,Registration_State, Issue_Date, Vechicle_Body_Type,Vehicle_Make and Violation_Time`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 Verify Issue_Date Column for the Range Values.\n",
    ">- Since ticket Issue Date is an critical attribute to assess the quality of the Dataset.\n",
    "Let us check if there are any missing values in the Issue Date column attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "| Min_IssueDate_2017| Max_IssueDate_2017|\n",
      "+-------------------+-------------------+\n",
      "|1972-03-30 00:00:00|2069-11-19 00:00:00|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the minimum & maximum issue_date range. to check for the 2017 records.\n",
    "sql_2=\"SELECT MIN(Issue_Date) AS Min_IssueDate_2017, MAX(Issue_Date) AS Max_IssueDate_2017\\\n",
    "       FROM tbl_nyctkt_2017\" \n",
    "\n",
    "spark.sql(sql_2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Observations***<br>\n",
    " - The Issue Tickets range between 30th March 1972 to 19th November 2069. Clearly this is Nonconforming. Let us Analyse column closely to decide optimal filter condition.\n",
    " - We will create two additional column issue_year and issue_month to create a new data frame.\n",
    " - Observe the distribution of year & month based on Issue_Date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9 Create Issue_Year & Issue_Month from Issue_Date Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+----------+-----------+\n",
      "|Summons_Number|         Issue_Date|Issue_Year|Issue_Month|\n",
      "+--------------+-------------------+----------+-----------+\n",
      "|    8539607141|2017-05-05 00:00:00|      2017|          5|\n",
      "|    8491667738|2017-03-01 00:00:00|      2017|          3|\n",
      "|    5094058873|2016-10-29 00:00:00|      2016|         10|\n",
      "|    8514570973|2017-06-21 00:00:00|      2017|          6|\n",
      "|    1414975570|2016-10-04 00:00:00|      2016|         10|\n",
      "+--------------+-------------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Additional Columns in the data frame Issue_Year and Issue_Month\n",
    "nyc_parking_tkt_2017 = nyc_parking_tkt_2017.withColumn(\"Issue_Year\",year(nyc_parking_tkt_2017.Issue_Date))\n",
    "nyc_parking_tkt_2017 = nyc_parking_tkt_2017.withColumn(\"Issue_Month\",month(nyc_parking_tkt_2017.Issue_Date))\n",
    "\n",
    "#print the new columns.\n",
    "nyc_parking_tkt_2017.select(\"Summons_Number\",\"Issue_Date\",\"Issue_Year\",\"Issue_Month\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.10 Re-Create Table View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re Create a Temporary View for analysis.\n",
    "nyc_parking_tkt_2017.createOrReplaceTempView(\"tbl_nyctkt_2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.11 Distribution of Year & Month of Issue_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------+\n",
      "|Issue_Year|Issue_Month|num_records|\n",
      "+----------+-----------+-----------+\n",
      "|      2017|          1|     877365|\n",
      "|      2017|          2|     826967|\n",
      "|      2017|          3|     964737|\n",
      "|      2017|          4|     888402|\n",
      "|      2017|          5|    1020244|\n",
      "|      2017|          6|     852187|\n",
      "|      2017|          7|        370|\n",
      "|      2017|          8|        309|\n",
      "|      2017|          9|        367|\n",
      "|      2017|         10|        274|\n",
      "|      2017|         11|        338|\n",
      "|      2017|         12|        358|\n",
      "+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### Observe the Distribution of Issue Date.\n",
    "sql_3=\"SELECT Issue_Year, Issue_Month, COUNT(*) AS num_records \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       WHERE ISSUE_Year =2017 \\\n",
    "       GROUP BY Issue_Year, Issue_Month \\\n",
    "       ORDER BY 1,2\" \n",
    "\n",
    "spark.sql(sql_3).show(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Observations***<br>\n",
    "- It is clear from the above query the parking Tickets have been Issued in year 2017 are between January, 2017 and December,2017.\n",
    "> - Filter the rows only required year 2017 for further Analysis.\n",
    "> - So, the total number of records after filtering for year 2017 is `5,431,918`.\n",
    "\n",
    "> ***Inference***<br>\n",
    "> - We will filtered data frame - the 2017  year - for our further ED Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.12 Filter rows based on Issue Date (Year & Month) for year 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (5431918, 12)\n"
     ]
    }
   ],
   "source": [
    "# Filter 2017 Fiscal Year Data.\n",
    "nyc_parking_tkt_2017_final = nyc_parking_tkt_2017\\\n",
    "                                  .filter((col(\"Issue_Year\") == 2017) & \\\n",
    "                                          ((col(\"Issue_Month\") >= 1)  | (col(\"Issue_Month\") <= 12))\n",
    "                                          ) \n",
    "\n",
    "# Check Dimensions.\n",
    "print(\"Shape: \",(nyc_parking_tkt_2017_final.count(),len(nyc_parking_tkt_2017_final.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re Create a Temporary View for analysis.\n",
    "nyc_parking_tkt_2017_final.createOrReplaceTempView(\"tbl_nyctkt_2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 : Overview and Examine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Question-1: Find the total number of tickets for the year "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Query for total Number of Tickets Received across all states in Year 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|Num_Tickets_2017|\n",
      "+----------------+\n",
      "|         5431918|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of ickets issued during year 2017.\n",
    "\n",
    "# SQL Query - sql_4\n",
    "sql_4 = \"SELECT count(*) as Num_Tickets_2017 FROM tbl_nyctkt_2017\"\n",
    "\n",
    "#Execute the Query.\n",
    "spark.sql(sql_4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Answer :\n",
    "> - The total number of Tickets issued for the fiscal year 2017 is `5,431,918`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Question-2: Find out the number of unique states from where the cars that got parking tickets came. (Hint: Use the column 'Registration State'.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Query for number of unique States which received maximum tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|Registration_State|Number_of_Tickets|\n",
      "+------------------+-----------------+\n",
      "|                NY|          4273951|\n",
      "|                NJ|           475825|\n",
      "|                PA|           140286|\n",
      "|                CT|            70403|\n",
      "|                FL|            69468|\n",
      "+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To find the maximum entries per registration state in Year 2017\n",
    "\n",
    "# SQL Query - sql_5\n",
    "sql_5=\"SELECT Registration_State, COUNT(*) AS Number_of_Tickets \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       WHERE year(Issue_Date) = 2017 \\\n",
    "       GROUP BY Registration_State \\\n",
    "       ORDER BY Number_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query.\n",
    "sql_5_result = spark.sql(sql_5) \n",
    "sql_5_result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Registration States: 65\n"
     ]
    }
   ],
   "source": [
    "# Check the number of unique entries.\n",
    "print(\"Number of Unique Registration States:\",sql_5_result.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations***<br>\n",
    "\n",
    "- From the initial analysis the number of unique states are `65`\n",
    "- There is an incorrect numerical entry `99`, which should be replaced with the state having maximum number of tickets.\n",
    "- It is clear from the above query results maximum number of registration entries are from `NY` State."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Query for the number of incorrect entry '99'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|Number_of_99_States|\n",
      "+-------------------+\n",
      "|              16055|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find number of entries with incorrect entry '99' in Registration State\n",
    "\n",
    "# SQL Query - sql_5\n",
    "sql_6=\"SELECT \\\n",
    "        COUNT(*) AS Number_of_99_States \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       WHERE (Registration_State = 99 AND year(Issue_Date) =2017)\"\n",
    "\n",
    "#Execute the Query.\n",
    "spark.sql(sql_6).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations***<br>\n",
    ">- There are `16055` entries with Numeric data `99` in  the Registration_State which needs to be replaced with `NY`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Replace the entry '99' with 'NY' in the data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing in Original Dataframe for Registration_State where Numeric data 99 with 'NY'.\n",
    "from pyspark.sql import functions as F\n",
    "nyc_parking_tkt_2017_final = nyc_parking_tkt_2017_final \\\n",
    "                                    .withColumn(\"Registration_State\", F.when(F.col(\"Registration_State\") == 99, 'NY') \\\n",
    "                                    .otherwise(F.col(\"Registration_State\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all 99 columns is replaced.\n",
    "nyc_parking_tkt_2017_final.where(col(\"Registration_State\") == 99).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Create Temporary View Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the View after replacing 99 in Registration State with 'NY'\n",
    "nyc_parking_tkt_2017_final.createOrReplaceTempView(\"tbl_nyctkt_2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Rerun Query for number of unique States which received maximum tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|Registration_State|Number_of_Tickets|\n",
      "+------------------+-----------------+\n",
      "|                NY|          4290006|\n",
      "|                NJ|           475825|\n",
      "|                PA|           140286|\n",
      "|                CT|            70403|\n",
      "|                FL|            69468|\n",
      "+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum entries per registration state in YearR 2017\n",
    "\n",
    "# SQL Query - sql_8\n",
    "sql_8=\"SELECT Registration_State, COUNT(*) AS Number_of_Tickets \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       WHERE year(Issue_Date) =2017 \\\n",
    "       GROUP BY Registration_State \\\n",
    "       ORDER BY Number_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query.\n",
    "sql_8_result = spark.sql(sql_8)\n",
    "sql_8_result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6 Verify Results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Registration States: 64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of unique entries post cleanup 99 entries.\n",
    "\n",
    "print(\"Number of Unique Registration States:\",sql_8_result.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Answer : :\n",
    "> - All incorrect `99` entries in Registration_State column have been replaced with maximum entry state value `NY`.\n",
    "> - Rerun the query again to find the entries for each registration states.\n",
    "> - The number of unique states from where the cars got parking tickets are `64`.\n",
    "> - The maximum number of tickets are received in the state of `NY`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3 : Aggregation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Question-1: How often does each violation code occur? Display the frequency of the top five violation codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Query for Top 5 Violation Codes (based on Frequency of Tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|Violation_Code|Number_of_Violations|\n",
      "+--------------+--------------------+\n",
      "|            21|              768087|\n",
      "|            36|              662765|\n",
      "|            38|              542079|\n",
      "|            14|              476664|\n",
      "|            20|              319646|\n",
      "+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the Top 5 Violation Cods for 2017.\n",
    "# SQL Query - sql_9\n",
    "sql_9=\"SELECT DISTINCT(Violation_Code), COUNT(*) AS Number_of_Violations \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       GROUP BY Violation_Code \\\n",
    "       ORDER BY Number_of_Violations DESC\"\n",
    "\n",
    "#Execute the Query and list out top 5.\n",
    "sql_9_result = spark.sql(sql_9)\n",
    "sql_9_result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage3: Q1: Answer : :\n",
    "> - The **`Top 5 Violation Codes and the frequencies`** are as below ;<br>\n",
    "        +--------------+--------------------+ \n",
    "        Violation_Code |Number_of_Violations| \n",
    "        +--------------+--------------------+ \n",
    "        |            21|              768087| \n",
    "        |            36|              662765| \n",
    "        |            38|              542079| \n",
    "        |            14|              476664| \n",
    "        |            20|              319646| \n",
    "        +--------------+--------------------+ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2: Question-2: How often does each 'vehicle body type' get a parking ticket? How about the 'vehicle make'? (Hint: Find the top 5 for both.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Query for Top 5 Vehicle body Type for the Year 2017 (based on Frequency of Tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|Vehicle_Body_Type|Frequency_of_Tickets|\n",
      "+-----------------+--------------------+\n",
      "|             SUBN|             1883954|\n",
      "|             4DSD|             1547312|\n",
      "|              VAN|              724029|\n",
      "|             DELV|              358984|\n",
      "|              SDN|              194197|\n",
      "+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the Top 5 Vehicle Body Type for 2017\n",
    "\n",
    "# SQL Query - sql_10\n",
    "sql_10=\"SELECT DISTINCT(Vehicle_Body_Type), COUNT(*) AS Frequency_of_Tickets \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       GROUP BY Vehicle_Body_Type \\\n",
    "       ORDER BY Frequency_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query and list out top 5.\n",
    "sql_10_result = spark.sql(sql_10)\n",
    "sql_10_result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Query for Top 5 Vehicle Make for the Year 2017 (based on Frequency of Tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|Vehicle_Make|Frequency_of_Tickets|\n",
      "+------------+--------------------+\n",
      "|        FORD|              636844|\n",
      "|       TOYOT|              605291|\n",
      "|       HONDA|              538884|\n",
      "|       NISSA|              462017|\n",
      "|       CHEVR|              356032|\n",
      "+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the Top 5 Vehicle Make for 2017\n",
    "\n",
    "# SQL Query - sql_11\n",
    "sql_11=\"SELECT DISTINCT(Vehicle_Make), COUNT(*) AS Frequency_of_Tickets \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       GROUP BY Vehicle_Make \\\n",
    "       ORDER BY Frequency_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query and list out top 5.\n",
    "sql_11_result = spark.sql(sql_11)\n",
    "sql_11_result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage3: Q2: Answer : :\n",
    "> - The **`Top 5 Vehicle Body Type for 2017 and the frequencies of tickets`** are as below ;<br>\n",
    "        +-----------------+--------------------+\n",
    "        |Vehicle_Body_Type|Frequency_of_Tickets|\n",
    "        +-----------------+--------------------+\n",
    "        |             SUBN|             1883954|\n",
    "        |             4DSD|             1547312|\n",
    "        |              VAN|              724029|\n",
    "        |             DELV|              358984|\n",
    "        |              SDN|              194197|\n",
    "        +-----------------+--------------------+\n",
    ">- The **`Top 5 Vehicle Make for 2017 and the frequencies of tickets`** are as below ;<br>\n",
    "        +------------+--------------------+\n",
    "        |Vehicle_Make|Frequency_of_Tickets|\n",
    "        +------------+--------------------+\n",
    "        |        FORD|              636844|\n",
    "        |       TOYOT|              605291|\n",
    "        |       HONDA|              538884|\n",
    "        |       NISSA|              462017|\n",
    "        |       CHEVR|              356032|\n",
    "        +------------+--------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3: Question-3:  A precinct is a police station that has a certain zone of the city under its command. Find the (5 highest) frequencies of tickets for each of the following;\n",
    ">- #### 1. 'Violation Precinct' (This is the precinct of the zone where the violation occurred). Using this, can you draw any insights for parking violations in any specific areas of the city?  \n",
    "> - #### 2. 'Issuer Precinct' (This is the precinct that issued the ticket.)\n",
    "> - #### Here, you would have noticed that the dataframe has the'Violating Precinct' or 'Issuing Precinct' as '0'. These are erroneous entries. Hence, you need to provide the records for five correct precincts. (Hint: Print the top six entries after sorting.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Query for Top 5 Violation Precinct (based on Frequency of Tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|Violation_Precinct|Frequency_of_Tickets|\n",
      "+------------------+--------------------+\n",
      "|                19|              274445|\n",
      "|                14|              203553|\n",
      "|                 1|              174702|\n",
      "|                18|              169131|\n",
      "|               114|              147444|\n",
      "+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Violation Precinct vs Frequency of Tickets.- \n",
    "\n",
    "# Find the Top 5 Violation Precinct for 2017\n",
    "\n",
    "# SQL Query - sql_12\n",
    "sql_12=\"SELECT DISTINCT(Violation_Precinct), COUNT(*) AS Frequency_of_Tickets \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       WHERE Violation_Precinct <> 0 \\\n",
    "       GROUP BY Violation_Precinct \\\n",
    "       ORDER BY Frequency_of_Tickets DESC\"\n",
    "\n",
    "\n",
    "#Execute the Query and list out top 5.\n",
    "sql_12_result = spark.sql(sql_12)\n",
    "sql_12_result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Query for Top 5 Issuer Precinct (based on Frequency of Tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|Issuer_Precinct|Frequency_of_Tickets|\n",
      "+---------------+--------------------+\n",
      "|             19|              266961|\n",
      "|             14|              200495|\n",
      "|              1|              168740|\n",
      "|             18|              162994|\n",
      "|            114|              144054|\n",
      "+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Issuer Precinct vs Frequency of Tickets:-\n",
    "\n",
    "# Find the Top 5 Issuer Precinct for 2017.\n",
    "# SQL Query - sql_13\n",
    "sql_13=\"SELECT DISTINCT(Issuer_Precinct), COUNT(*) AS Frequency_of_Tickets \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       WHERE Issuer_Precinct <> 0 \\\n",
    "       GROUP BY Issuer_Precinct \\\n",
    "       ORDER BY Frequency_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query and list out top 5.\n",
    "sql_13_result = spark.sql(sql_13)\n",
    "sql_13_result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage3: Q3: Answer : :\n",
    "> - 1. The **`Top 5 Violation Precinct for 2017 and the frequencies of tickets`** are as below ;<br>\n",
    "            +------------------+--------------------+\n",
    "            |Violation_Precinct|Frequency_of_Tickets|\n",
    "            +------------------+--------------------+\n",
    "            |                19|              274445|\n",
    "            |                14|              203553|\n",
    "            |                 1|              174702|\n",
    "            |                18|              169131|\n",
    "            |               114|              147444|\n",
    "            +------------------+--------------------+\n",
    "> - 2. The **`Top 5 Issuer Precinct for 2017 and the frequencies of tickets`** are as below ;<br>\n",
    "            +---------------+--------------------+\n",
    "            |Issuer_Precinct|Frequency_of_Tickets|\n",
    "            +---------------+--------------------+\n",
    "            |             19|              266961|\n",
    "            |             14|              200495|\n",
    "            |              1|              168740|\n",
    "            |             18|              162994|\n",
    "            |            114|              144054|\n",
    "            +---------------+--------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4: Question-4: Find the violation code frequencies for three precincts that have issued the most number of tickets. Do these precinct zones have an exceptionally high frequency of certain violation codes? Are these codes common across precincts? \n",
    ">- #### (Hint: In the SQL view, use the 'where' attribute to filter among three precincts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Query the Voilation Code Frequencies for three Top Precints (19,14 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+--------------------+\n",
      "|Violation_Code|Issuer_Precinct|Frequency_of_Tickets|\n",
      "+--------------+---------------+--------------------+\n",
      "|            46|             19|               48445|\n",
      "|            38|             19|               36386|\n",
      "|            37|             19|               36056|\n",
      "|            14|             19|               29797|\n",
      "|            21|             19|               28415|\n",
      "+--------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+---------------+--------------------+\n",
      "|Violation_Code|Issuer_Precinct|Frequency_of_Tickets|\n",
      "+--------------+---------------+--------------------+\n",
      "|            14|             14|               45036|\n",
      "|            69|             14|               30464|\n",
      "|            31|             14|               22555|\n",
      "|            47|             14|               18364|\n",
      "|            42|             14|               10027|\n",
      "+--------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+---------------+--------------------+\n",
      "|Violation_Code|Issuer_Precinct|Frequency_of_Tickets|\n",
      "+--------------+---------------+--------------------+\n",
      "|            14|              1|               38354|\n",
      "|            16|              1|               19081|\n",
      "|            20|              1|               15408|\n",
      "|            46|              1|               12745|\n",
      "|            38|              1|                8535|\n",
      "+--------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Violation Code Distribution in Top three Issuer precincts.\n",
    "\n",
    "# Find the Top 3 Violation Codes for Issuer precients in the year 2017.\n",
    "\n",
    "# Note: \n",
    "#  The Top Three issuer precincts based on the frequency of the tickets (as per the question 3) are 19, 14 and 1.\n",
    "#\n",
    "\n",
    "# Violation Codes for the Issuer precinct 19.\n",
    "# SQL Query - sql_14\n",
    "sql_14=\"SELECT DISTINCT(Violation_Code), Issuer_Precinct, COUNT(*)  AS Frequency_of_Tickets \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       WHERE Issuer_Precinct = 19  \\\n",
    "       GROUP BY Issuer_Precinct, Violation_Code \\\n",
    "       ORDER BY Frequency_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query and list out top 5.\n",
    "sql_14_result = spark.sql(sql_14)\n",
    "sql_14_result.show(5)\n",
    "\n",
    "\n",
    "# Violation Codes for the Issuer precinct 14.\n",
    "# SQL Query - sql_15\n",
    "sql_15=\"SELECT DISTINCT(Violation_Code), Issuer_Precinct, COUNT(*) AS Frequency_of_Tickets \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       WHERE Issuer_Precinct = 14  \\\n",
    "       GROUP BY Issuer_Precinct, Violation_Code  \\\n",
    "       ORDER BY Frequency_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query and list out top 5.\n",
    "sql_15_result = spark.sql(sql_15)\n",
    "sql_15_result.show(5)\n",
    "\n",
    "\n",
    "# Violation Codes for the Issuer precinct 1.\n",
    "# SQL Query - sql_16\n",
    "sql_16=\"SELECT DISTINCT(Violation_Code), Issuer_Precinct, COUNT(*) AS Frequency_of_Tickets \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       WHERE Issuer_Precinct = 1  \\\n",
    "       GROUP BY Issuer_Precinct, Violation_Code \\\n",
    "       ORDER BY Frequency_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query and list out top 5.\n",
    "sql_16_result = spark.sql(sql_16)\n",
    "sql_16_result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Query the Other Violation and their Frequency for Comparison (other than 19,14 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|Violation_Code|Frequency_of_Tickets|\n",
      "+--------------+--------------------+\n",
      "|            21|              734588|\n",
      "|            36|              662765|\n",
      "|            38|              493889|\n",
      "|            14|              363477|\n",
      "|            20|              286848|\n",
      "+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Violation Codes for the Issuer precinct other than 19,14 and 1.\n",
    "# SQL Query - sql_17\n",
    "sql_17=\"SELECT DISTINCT(Violation_Code), COUNT(*) AS Frequency_of_Tickets \\\n",
    "       FROM tbl_nyctkt_2017 \\\n",
    "       WHERE Issuer_Precinct NOT IN (19,14,1)  \\\n",
    "       GROUP BY Violation_Code \\\n",
    "       ORDER BY Frequency_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query and list out .\n",
    "sql_17_result = spark.sql(sql_17)\n",
    "sql_17_result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage3: Q4: Answer : :\n",
    "> - The Top 3   precincts are 19,14,1.\n",
    "    - For Issuer Precinct 19 - Violation Codes are 46,38,37,14 and 21 \n",
    "    - For Issuer Precinct 14 - Violation Codes are 14,69,31,47 and 42 \n",
    "    - For Issuer Precinct 1  - Violation Codes are 14,16,20,46 and 38 \n",
    "> - Only Violation Code which is common across other Issues Preceints (not 19,14 and 1) is 14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5: Question-5:Find out the properties of parking violations across different times of the day:\n",
    ">-  **Find a way to deal with missing values, if any. <br> (Hint: Check for the null values using 'isNull' under the SQL. Also, to remove the null values, check the 'dropna' command in the API documentation.)**<br><br>\n",
    ">  **1. The Violation Time field is specified in a strange format. Find a way to make this a time attribute that you can use to divide into groups.**<br><br>\n",
    "> **2. Divide 24 hours into six equal discrete bins of time. Choose the intervals as you see fit. For each of these groups, find the three most commonly occurring violations.\n",
    "(Hint: Use the CASE-WHEN in SQL view to segregate into bins. To find the most commonly occurring violations, you can use an approach similar to the one mentioned in the hint for question 4.)**<br><br>\n",
    "> **3. Now, try another direction. For the three most commonly occurring violation codes, find the most common time of the day (in terms of the bins from the previous part).**<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1 Check for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+----------+-----------+\n",
      "|Summons_Number|Plate_ID|Registration_State|Issue_Date|Violation_Code|Vehicle_Body_Type|Vehicle_Make|Violation_Precinct|Issuer_Precinct|Violation_Time|Issue_Year|Issue_Month|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+----------+-----------+\n",
      "|             0|       0|                 0|         0|             0|                0|           0|                 0|              0|             0|         0|          0|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify for NULL values in the data frame using functions.\n",
    "nyc_parking_tkt_2017_final.select([count(when(col(c).isNull(), c)).alias(c) \\\n",
    "                                   for c in nyc_parking_tkt_2017_final.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2 Fix the format of Violation_Time column and convert the type to 24 hour Timestamp format\n",
    "> - We can observe that the string format of the time attributes include only a partial component of AM/PM. Therefore we will append M to the end of each time attribute before converting it into a `24 Hour AM/PM timestamp format`.<br><br>\n",
    "> - Also, following needs to be fixed for Violation_Time Column before converting to appropriate unix time stamp format ;\n",
    "    - Imputing of all `0000A` and `0000P` in to `1200AM` and `1200PM` respectively.\n",
    "    - Imputing of all Null values to `1200A`\n",
    "    - There are values which does not `A` or `P`, so impute them with `A` as default value.\n",
    "    - Impute column values which are less than 5 characters in to appropriate format\n",
    "    - Impute column values starting with `00` and `12`\n",
    "    - Impute special characters such as `+ (plus) , - (hyphen) , . (dot) , (backslash)`.\n",
    "    - Impute four digit wrong value `015A`,`113 A` and `113 P` to five digits value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are inconsistencies in the Violation_Time Column\n",
    "# The data to be corrected before converted to appropriate 24 hour Timestamp format\n",
    "\n",
    "suffix_char = \"A\"\n",
    "nyc_parking_tkt_2017_fmt = nyc_parking_tkt_2017_final.withColumn(\"Violation_Time\",\\\n",
    "                            F.when(col(\"Violation_Time\") == '0000A', '1200A')\\\n",
    "                             .when(col(\"Violation_Time\") == '0000P', '1200P')\\\n",
    "                             .when(col(\"Violation_Time\")  ==  'nan', '1200A') \\\n",
    "                             .when(~(nyc_parking_tkt_2017_final[\"Violation_Time\"].contains(\"A\") |\\\n",
    "                                     nyc_parking_tkt_2017_final[\"Violation_Time\"].contains(\"P\")),\\\n",
    "                                    concat(col(\"Violation_Time\"),lit(suffix_char))) \\\n",
    "                             .when(nyc_parking_tkt_2017_final.Violation_Time.substr(0,2) > '12', \\\n",
    "                                                      regexp_replace('Violation_Time','^[0-9]{2}','12'))\\\n",
    "                             .when(col(\"Violation_Time\")  == '015A',  '0150A')\\\n",
    "                             .when(col(\"Violation_Time\")  == '113 A', '1130A')\\\n",
    "                             .when(col(\"Violation_Time\")  == '113 P', '1130P')\\\n",
    "                             .otherwise(col(\"Violation_Time\")) \\\n",
    "                             )\n",
    "                                                                 \n",
    "# Remove Special character such +,-,.,`, etc from Violation_Time column.\n",
    "nyc_parking_tkt_2017_df = nyc_parking_tkt_2017_fmt.withColumn(\"Violation_Time\", \\\n",
    "                                                regexp_replace('Violation_Time','[\\+.*$,\\.*$,\\/.*$,\\`.*$]','0'))\n",
    "\n",
    "# Correct 00XXAM and 00XXPM to appropriate 12XXAM and 12XXPM respectively (24 hour format).\n",
    "nyc_parking_tkt_2017_df = nyc_parking_tkt_2017_df.withColumn(\"Violation_Time\", \\\n",
    "                                                regexp_replace('Violation_Time','^0{2}','12'))\n",
    "\n",
    "#Suffix the time having 'A' and 'P' with literal 'M'\n",
    "suffix_char = \"M\"\n",
    "nyc_parking_tkt_2017_df = nyc_parking_tkt_2017_df.withColumn(\"Violation_Time\",\\\n",
    "                                                concat(col(\"Violation_Time\"),lit(suffix_char)))\n",
    "\n",
    "#Impute 1 row having incorrect timestamp value to appropriate one.\n",
    "nyc_parking_tkt_2017_df = nyc_parking_tkt_2017_df.withColumn(\"Violation_Time\",\\\n",
    "                        when(col(\"Violation_Time\") == '04080AM', '0408AM').otherwise(col(\"Violation_Time\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3 convert the type to 24 hour Timestamp format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column Violation_Time to new column Violation_Timestamp with format 24 hour AM/PM Unix Timestamp format .\n",
    "import pyspark.sql.functions as F\n",
    "nyc_parking_tkt_2017_df = nyc_parking_tkt_2017_df  \\\n",
    "            .withColumn(\"Violation_Time_Timestamp\", \\\n",
    "                F.from_unixtime(F.unix_timestamp(\"Violation_Time\",\"hhmma\"),'HH:mm:ss a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+------------------------+\n",
      "|Summons_Number|Violation_Time|Violation_Time_TimeStamp|\n",
      "+--------------+--------------+------------------------+\n",
      "+--------------+--------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate any invalid translation during conversion into 24 hour format.\n",
    "nyc_parking_tkt_2017_df.select(\"Summons_Number\",\"Violation_Time\",\n",
    "                               \"Violation_Time_TimeStamp\").where(\"Violation_Time_Timestamp is NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+------------------------+\n",
      "|Summons_Number|Violation_Time|Violation_Time_Timestamp|\n",
      "+--------------+--------------+------------------------+\n",
      "|    1131600721|        0751AM|             07:51:00 AM|\n",
      "|    1131601841|        1105AM|             11:05:00 AM|\n",
      "|    1253083198|        0423AM|             04:23:00 AM|\n",
      "|    1314438890|        0546PM|             17:46:00 PM|\n",
      "|    1340663107|        1145AM|             11:45:00 AM|\n",
      "+--------------+--------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_parking_tkt_2017_df.select('Summons_Number','Violation_Time','Violation_Time_Timestamp').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.4 Create Violation_Hour,Violation_Min and Violation_AMPM for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------------+--------------+-------------+--------------+\n",
      "|Violation_Time|Violation_Time_Timestamp|Violation_Hour|Violation_Min|Violation_AMPM|\n",
      "+--------------+------------------------+--------------+-------------+--------------+\n",
      "|        0751AM|             07:51:00 AM|             7|           51|            AM|\n",
      "|        1105AM|             11:05:00 AM|            11|            5|            AM|\n",
      "|        0423AM|             04:23:00 AM|             4|           23|            AM|\n",
      "|        0546PM|             17:46:00 PM|            17|           46|            PM|\n",
      "|        1145AM|             11:45:00 AM|            11|           45|            AM|\n",
      "|        1210AM|             00:10:00 AM|             0|           10|            AM|\n",
      "|        0111PM|             13:11:00 PM|            13|           11|            PM|\n",
      "|        1021AM|             10:21:00 AM|            10|           21|            AM|\n",
      "|        0810AM|             08:10:00 AM|             8|           10|            AM|\n",
      "|        0815AM|             08:15:00 AM|             8|           15|            AM|\n",
      "|        0445AM|             04:45:00 AM|             4|           45|            AM|\n",
      "|        0915PM|             21:15:00 PM|            21|           15|            PM|\n",
      "|        1140AM|             11:40:00 AM|            11|           40|            AM|\n",
      "|        0945AM|             09:45:00 AM|             9|           45|            AM|\n",
      "|        0221AM|             02:21:00 AM|             2|           21|            AM|\n",
      "|        1122PM|             23:22:00 PM|            23|           22|            PM|\n",
      "|        1050PM|             22:50:00 PM|            22|           50|            PM|\n",
      "|        1221PM|             12:21:00 PM|            12|           21|            PM|\n",
      "|        1204PM|             12:04:00 PM|            12|            4|            PM|\n",
      "|        0928PM|             21:28:00 PM|            21|           28|            PM|\n",
      "+--------------+------------------------+--------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create new column Violation_Hour,Violation_Min and Violation_AMPM\n",
    "nyc_parking_tkt_2017_df = nyc_parking_tkt_2017_df\\\n",
    "           .withColumn(\"Violation_Hour\",nyc_parking_tkt_2017_df.Violation_Time_Timestamp.substr(0,2).cast(\"int\")) \\\n",
    "           .withColumn(\"Violation_Min\",nyc_parking_tkt_2017_df.Violation_Time_Timestamp.substr(4,2).cast(\"int\"))  \\\n",
    "           .withColumn(\"Violation_AMPM\",nyc_parking_tkt_2017_df.Violation_Time_Timestamp.substr(10,2)) \\\n",
    "        \n",
    "# Check the results\n",
    "nyc_parking_tkt_2017_df.select(\"Violation_Time\",\"Violation_Time_Timestamp\",\"Violation_Hour\",\n",
    "                                          \"Violation_Min\",\"Violation_AMPM\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Violation_Hour|\n",
      "+--------------+\n",
      "|            23|\n",
      "|            22|\n",
      "|            21|\n",
      "|            20|\n",
      "|            19|\n",
      "|            18|\n",
      "|            17|\n",
      "|            16|\n",
      "|            15|\n",
      "|            14|\n",
      "|            13|\n",
      "|            12|\n",
      "|            11|\n",
      "|            10|\n",
      "|             9|\n",
      "|             8|\n",
      "|             7|\n",
      "|             6|\n",
      "|             5|\n",
      "|             4|\n",
      "|             3|\n",
      "|             2|\n",
      "|             1|\n",
      "|             0|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_parking_tkt_2017_df.select(\"Violation_Hour\").distinct().sort(\"Violation_Hour\",ascending=False).show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.5  Divide 24 hours into six equal discrete bins of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the Temp View after Fixing Violation_Time  Format.\n",
    "nyc_parking_tkt_2017_df.createOrReplaceTempView(\"tbl_nyctkt_2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+------------------+\n",
      "|Violation_Hour|Violation_Code|Violation_Hour_Bin|\n",
      "+--------------+--------------+------------------+\n",
      "|             7|            17|        bin_4_to_7|\n",
      "|            11|            74|       bin_8_to_11|\n",
      "|             4|            21|        bin_4_to_7|\n",
      "|            17|            14|      bin_16_to_19|\n",
      "|            11|            67|       bin_8_to_11|\n",
      "+--------------+--------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide 24 hours into 6 equal discrete bins of time. The intervals you choose are at your discretion.\n",
    "\n",
    "# SQL Query - sql_18\n",
    "sql_18 = \"SELECT Violation_Hour,Violation_Code,\\\n",
    "            CASE \\\n",
    "                WHEN Violation_Hour BETWEEN  0 AND  3 THEN 'bin_0_to_3'   \\\n",
    "                WHEN Violation_Hour BETWEEN  4 AND  7 THEN 'bin_4_to_7'   \\\n",
    "                WHEN Violation_Hour BETWEEN  8 AND 11 THEN 'bin_8_to_11'  \\\n",
    "                WHEN Violation_Hour BETWEEN 12 AND 15 THEN 'bin_12_to_15' \\\n",
    "                WHEN Violation_Hour BETWEEN 16 AND 19 THEN 'bin_16_to_19' \\\n",
    "                WHEN Violation_Hour BETWEEN 20 AND 23 THEN 'bin_20_to_23' \\\n",
    "                END AS Violation_Hour_Bin \\\n",
    "          FROM tbl_nyctkt_2017\"\n",
    "\n",
    "\n",
    "#Execute the Query and list out .\n",
    "sql_18_result = spark.sql(sql_18)\n",
    "sql_18_result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.6  Create Temporary View Table for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Temporary View Table based on the resultset.\n",
    "sql_18_result.createOrReplaceTempView(\"tbl_violation_hour_bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.7  Query to find the three most commonly occurring violations (based on above Violation_Hour_Bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+--------------------+---+\n",
      "|Violation_Hour_Bin|Violation_Code|Frequency_of_Tickets|Rnk|\n",
      "+------------------+--------------+--------------------+---+\n",
      "|        bin_0_to_3|            21|               36958|  1|\n",
      "|        bin_0_to_3|            40|               25867|  2|\n",
      "|        bin_0_to_3|            78|               15528|  3|\n",
      "|      bin_16_to_19|            38|              102855|  1|\n",
      "|      bin_16_to_19|            14|               75902|  2|\n",
      "|      bin_16_to_19|            37|               70345|  3|\n",
      "|        bin_4_to_7|            14|               74114|  1|\n",
      "|        bin_4_to_7|            40|               60652|  2|\n",
      "|        bin_4_to_7|            21|               57897|  3|\n",
      "|      bin_20_to_23|             7|               26293|  1|\n",
      "|      bin_20_to_23|            40|               22337|  2|\n",
      "|      bin_20_to_23|            14|               21045|  3|\n",
      "|       bin_8_to_11|            21|              598070|  1|\n",
      "|       bin_8_to_11|            36|              348165|  2|\n",
      "|       bin_8_to_11|            38|              176570|  3|\n",
      "|      bin_12_to_15|            36|              286284|  1|\n",
      "|      bin_12_to_15|            38|              240722|  2|\n",
      "|      bin_12_to_15|            37|              167026|  3|\n",
      "+------------------+--------------+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Query - sql_19\n",
    "sql_19 = \"SELECT Violation_Hour_Bin, \\\n",
    "                 Violation_Code, \\\n",
    "                 Frequency_of_Tickets, \\\n",
    "                 Rnk \\\n",
    "                 FROM(SELECT \\\n",
    "                        A.Violation_Hour_Bin, \\\n",
    "                        A.Violation_Code, \\\n",
    "                        A.Frequency_of_Tickets, \\\n",
    "                        DENSE_RANK() OVER(PARTITION BY A.Violation_Hour_Bin ORDER BY A.Frequency_of_Tickets DESC) AS Rnk \\\n",
    "                    FROM (SELECT \\\n",
    "                              Violation_Hour_Bin, \\\n",
    "                              Violation_Code, \\\n",
    "                              COUNT(*) AS Frequency_of_Tickets \\\n",
    "                          FROM tbl_violation_hour_bin \\\n",
    "                          GROUP BY Violation_Hour_Bin, Violation_Code ) AS A \\\n",
    "                     ) \\\n",
    "                 WHERE Rnk <=3\"  \n",
    "            \n",
    "#Execute the Query and list out .\n",
    "sql_19_result = spark.sql(sql_19)\n",
    "sql_19_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.8  Query to find out Three most commonly occurring violation codes in the year 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+\n",
      "|Violation_Code|Number_of_Tickets|\n",
      "+--------------+-----------------+\n",
      "|            21|           768087|\n",
      "|            36|           662765|\n",
      "|            38|           542079|\n",
      "+--------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Query - sql_20\n",
    "sql_20 = \"SELECT Violation_Code, COUNT(*) AS Number_of_Tickets \\\n",
    "          FROM tbl_violation_hour_bin \\\n",
    "          GROUP BY Violation_Code \\\n",
    "          ORDER BY Number_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query and list out .\n",
    "sql_20_result = spark.sql(sql_20)\n",
    "sql_20_result.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations***<br>\n",
    "\n",
    "- The Top three Violation Codes based on Number of Tickets for the Year 2017 are `21`, `36` and `38`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.9  Query Find out most common time of the day these three (21,36 and 38).(based on bins from above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+-----------------+\n",
      "|Violation_Code|Violation_Hour_Bin|Number_of_Tickets|\n",
      "+--------------+------------------+-----------------+\n",
      "|            21|        bin_0_to_3|            36958|\n",
      "|            21|      bin_12_to_15|            74719|\n",
      "|            21|      bin_16_to_19|              259|\n",
      "|            21|      bin_20_to_23|              184|\n",
      "|            21|        bin_4_to_7|            57897|\n",
      "|            21|       bin_8_to_11|           598070|\n",
      "|            36|      bin_12_to_15|           286284|\n",
      "|            36|      bin_16_to_19|            13534|\n",
      "|            36|        bin_4_to_7|            14782|\n",
      "|            36|       bin_8_to_11|           348165|\n",
      "|            38|        bin_0_to_3|              312|\n",
      "|            38|      bin_12_to_15|           240722|\n",
      "|            38|      bin_16_to_19|           102855|\n",
      "|            38|      bin_20_to_23|            20347|\n",
      "|            38|        bin_4_to_7|             1273|\n",
      "|            38|       bin_8_to_11|           176570|\n",
      "+--------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Query - sql_21\n",
    "sql_21 = \"SELECT Violation_Code, Violation_Hour_Bin, COUNT(*) AS Number_of_Tickets \\\n",
    "          FROM tbl_violation_hour_bin \\\n",
    "          WHERE Violation_Code IN (21,36,38) \\\n",
    "          GROUP BY Violation_Code,Violation_Hour_Bin \\\n",
    "          ORDER BY Violation_Code,Violation_Hour_Bin,Number_of_Tickets DESC\"\n",
    "\n",
    "#Execute the Query and list out .\n",
    "sql_21_result = spark.sql(sql_21)\n",
    "sql_21_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage3: Q5: Answer : :\n",
    "> -  **There are no missing or NULL Values in the data.**<br>\n",
    ">  **1. The Violation Time column is cleaned and formatted correctly , so that it is converted to apprproiate 24 hour timestamp format. New columns Violation_Hours, Violation_Min and Violation_AMPM created for analysis.**<br>\n",
    ">  **2.  The data is divided in to 6 different bins based on Violation_Hour (3 hour window) using SQL Query using CASE..WHEN.**<br>\n",
    ">  **3. Finally, 3 most commonly occuring Violation Codes identified, based each of the bins obtained from step 2.**\n",
    "\n",
    "> -  The resultset for the three most commonly occuring violation codes for based on each of bins and their ranking as below;\n",
    "                    +------------------+--------------+--------------------+---+\n",
    "                    |Violation_Hour_Bin|Violation_Code|Frequency_of_Tickets|Rnk|\n",
    "                    +------------------+--------------+--------------------+---+\n",
    "                    |        bin_0_to_3|            21|               36958|  1|\n",
    "                    |        bin_0_to_3|            40|               25867|  2|\n",
    "                    |        bin_0_to_3|            78|               15528|  3|\n",
    "                    |      bin_16_to_19|            38|              102855|  1|\n",
    "                    |      bin_16_to_19|            14|               75902|  2|\n",
    "                    |      bin_16_to_19|            37|               70345|  3|\n",
    "                    |        bin_4_to_7|            14|               74114|  1|\n",
    "                    |        bin_4_to_7|            40|               60652|  2|\n",
    "                    |        bin_4_to_7|            21|               57897|  3|\n",
    "                    |      bin_20_to_23|             7|               26293|  1|\n",
    "                    |      bin_20_to_23|            40|               22337|  2|\n",
    "                    |      bin_20_to_23|            14|               21045|  3|\n",
    "                    |       bin_8_to_11|            21|              598070|  1|\n",
    "                    |       bin_8_to_11|            36|              348165|  2|\n",
    "                    |       bin_8_to_11|            38|              176570|  3|\n",
    "                    |      bin_12_to_15|            36|              286284|  1|\n",
    "                    |      bin_12_to_15|            38|              240722|  2|\n",
    "                    |      bin_12_to_15|            37|              167026|  3|\n",
    "                    +------------------+--------------+--------------------+---+                 \n",
    "> - The three most commonly occurring violation codes, find the most common time of the day (in terms of the bins from the previous part).\n",
    "                            +--------------+------------------+-----------------+\n",
    "                            |Violation_Code|Violation_Hour_Bin|Number_of_Tickets|\n",
    "                            +--------------+------------------+-----------------+\n",
    "                            |            21|        bin_0_to_3|            36958|\n",
    "                            |            21|      bin_12_to_15|            74719|\n",
    "                            |            21|      bin_16_to_19|              259|\n",
    "                            |            21|      bin_20_to_23|              184|\n",
    "                            |            21|        bin_4_to_7|            57897|\n",
    "                            |            21|       bin_8_to_11|           598070|\n",
    "                            |            36|      bin_12_to_15|           286284|\n",
    "                            |            36|      bin_16_to_19|            13534|\n",
    "                            |            36|        bin_4_to_7|            14782|\n",
    "                            |            36|       bin_8_to_11|           348165|\n",
    "                            |            38|        bin_0_to_3|              312|\n",
    "                            |            38|      bin_12_to_15|           240722|\n",
    "                            |            38|      bin_16_to_19|           102855|\n",
    "                            |            38|      bin_20_to_23|            20347|\n",
    "                            |            38|        bin_4_to_7|             1273|\n",
    "                            |            38|       bin_8_to_11|           176570|\n",
    "                            +--------------+------------------+-----------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6: Question-6:Let’s try and find some seasonality in this data:<br>\n",
    ">- ** First, divide the year into a certain number of seasons, and find the frequencies of tickets for each season. (Hint: Use Issue Date to segregate into seasons.)**<br>\n",
    "\n",
    ">- ** Then, find the three most common violations for each of these seasons.\n",
    "(Hint: You can use an approach similar to the one mentioned in the hint for question 4.)** </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations***\n",
    "> #### Checking for seasonality in dataset :#### \n",
    "> - ***Divide the Issue_Year in to 4 Seasons - Winter, Spring, Summer and Fall.*** \n",
    "> - ***Find the Frequency of Tickets in each of the Season.***\n",
    "> - ***Then, find the three most common violations for each of these seasons.***\n",
    "> - **Note:** We have already split the `Issue_Date` in to `Issue_Year` and `Issue_Month` in the `Stage-1 [Section:1.9]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.1 Query to Divide the Issue_Month in to 4 Seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+------+\n",
      "|Summons_Number|Violation_Code|Season|\n",
      "+--------------+--------------+------+\n",
      "|    8539607141|            46|Spring|\n",
      "|    8491667738|            19|Spring|\n",
      "|    8514570973|            21|Summer|\n",
      "|    8348055757|            21|Spring|\n",
      "|    8471227990|            50|Spring|\n",
      "+--------------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Query - sql_22\n",
    "sql_22 = \"SELECT Summons_Number, Violation_Code,\\\n",
    "          CASE \\\n",
    "             WHEN Issue_Month IN (1,2,12)      THEN 'Winter' \\\n",
    "             WHEN Issue_Month BETWEEN 3 AND 5  THEN 'Spring' \\\n",
    "             WHEN Issue_Month BETWEEN 6 AND 8  THEN 'Summer' \\\n",
    "             WHEN Issue_Month BETWEEN 9 AND 11 THEN 'Fall'   \\\n",
    "          END AS Season \\\n",
    "          FROM tbl_nyctkt_2017\"\n",
    "\n",
    "#Execute the Query and list out .\n",
    "sql_22_result = spark.sql(sql_22)\n",
    "sql_22_result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.2 Create Temporary View Table for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Temp View .\n",
    "sql_22_result.createOrReplaceTempView(\"tbl_seasons_nyctkt_2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.3 Query to Find the Frequency of Tickets in each of the Seasons in Year 2017 from the Temporary View Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|Season|Frequency_of_Tickets|\n",
      "+------+--------------------+\n",
      "|Spring|             2873383|\n",
      "|Winter|             1704690|\n",
      "|Summer|              852866|\n",
      "|  Fall|                 979|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Query - sql_23\n",
    "sql_23 = \"SELECT Season,COUNT(*) AS Frequency_of_Tickets \\\n",
    "          FROM tbl_seasons_nyctkt_2017 \\\n",
    "          GROUP BY Season \\\n",
    "          ORDER BY Frequency_of_Tickets DESC \"\n",
    "\n",
    "#Execute the Query and list out .\n",
    "sql_23_result = spark.sql(sql_23)\n",
    "sql_23_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.4 Query to find the three most common violations for each of the seasons as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+--------------------+----+\n",
      "|Season|Violation_Code|Frequency_of_Tickets|Rank|\n",
      "+------+--------------+--------------------+----+\n",
      "|Spring|            21|              402424|   1|\n",
      "|Spring|            36|              344834|   2|\n",
      "|Spring|            38|              271167|   3|\n",
      "|Summer|            21|              127352|   1|\n",
      "|Summer|            36|               96663|   2|\n",
      "|Summer|            38|               83518|   3|\n",
      "|  Fall|            46|                 231|   1|\n",
      "|  Fall|            21|                 128|   2|\n",
      "|  Fall|            40|                 116|   3|\n",
      "|Winter|            21|              238183|   1|\n",
      "|Winter|            36|              221268|   2|\n",
      "|Winter|            38|              187386|   3|\n",
      "+------+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Query - sql_24\n",
    "sql_24 = \"SELECT Season, \\\n",
    "                 Violation_Code, \\\n",
    "                 Frequency_of_Tickets, \\\n",
    "                 Rank \\\n",
    "          FROM (SELECT DENSE_RANK() OVER(PARTITION BY A.Season ORDER BY A.Frequency_of_Tickets DESC) AS Rank, \\\n",
    "                       A.Season, \\\n",
    "                       A.Violation_Code, \\\n",
    "                       A.Frequency_of_Tickets \\\n",
    "                FROM (SELECT \\\n",
    "                         Season, \\\n",
    "                         Violation_Code, \\\n",
    "                         COUNT(*) AS Frequency_of_Tickets \\\n",
    "                      FROM tbl_seasons_nyctkt_2017 \\\n",
    "                      GROUP BY Season, Violation_Code \\\n",
    "                     ) AS A \\\n",
    "                ) \\\n",
    "           WHERE Rank <= 3\"\n",
    "         \n",
    "#Execute the Query and list out .\n",
    "sql_24_result = spark.sql(sql_24)\n",
    "sql_24_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage3: Q6: Answer : :\n",
    "> -  **Divided the Issue Month in 4 Season bins as `Winter`,`Spring`,`Summer` and `Fall`.** \n",
    "> - **The Frequencies of Tickets for each of the seasons  are as below ;**\n",
    "                    +------+--------------------+\n",
    "                    |Season|Frequency_of_Tickets|\n",
    "                    +------+--------------------+\n",
    "                    |Spring|             2873383|\n",
    "                    |Winter|             1704690|\n",
    "                    |Summer|              852866|\n",
    "                    |  Fall|                 979|\n",
    "                    +------+--------------------+\n",
    ">- **The three most common violations for each of the season are as below;**\n",
    "                    +------+--------------+--------------------+----+\n",
    "                    |Season|Violation_Code|Frequency_of_Tickets|Rank|\n",
    "                    +------+--------------+--------------------+----+\n",
    "                    |Spring|            21|              402424|   1|\n",
    "                    |Spring|            36|              344834|   2|\n",
    "                    |Spring|            38|              271167|   3|\n",
    "                    |Summer|            21|              127352|   1|\n",
    "                    |Summer|            36|               96663|   2|\n",
    "                    |Summer|            38|               83518|   3|\n",
    "                    |  Fall|            46|                 231|   1|\n",
    "                    |  Fall|            21|                 128|   2|\n",
    "                    |  Fall|            40|                 116|   3|\n",
    "                    |Winter|            21|              238183|   1|\n",
    "                    |Winter|            36|              221268|   2|\n",
    "                    |Winter|            38|              187386|   3|\n",
    "                    +------+--------------+--------------------+----+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6: Question-7:The fines collected from all the instances of parking violation constitute a source of revenue for the NYC Police Department. Let’s take an example of estimating this for the three most commonly occurring codes:<br>\n",
    ">**1. Find the total occurrences of the three most common violation codes.**<br>\n",
    ">**2. Then, visit the website:http://www1.nyc.gov/site/finance/vehicles/services-violation-codes.page. It lists the fines associated with different violation codes. They’re divided into two categories:**\n",
    ">   - **one for the highest-density locations in the city and the other for the rest of the city.**\n",
    ">   - **For the sake of simplicity, take the average of the two.**\n",
    "\n",
    ">**3. Using this information, find the total amount collected for the three violation codes with the maximum tickets. State the code that has the highest total collection.**<br>\n",
    ">**4. What can you intuitively infer from these findings?**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.1 Query to Find the total occurrences of the three most common violation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|Violation_Code|Frequency_of_Tickets|\n",
      "+--------------+--------------------+\n",
      "|            21|              768087|\n",
      "|            36|              662765|\n",
      "|            38|              542079|\n",
      "+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Query - sql_25\n",
    "sql_25 = \"SELECT Violation_Code,COUNT(*) AS Frequency_of_Tickets \\\n",
    "          FROM tbl_nyctkt_2017 \\\n",
    "          GROUP BY Violation_Code \\\n",
    "          ORDER BY Frequency_of_Tickets DESC LIMIT 3\"\n",
    "\n",
    "#Execute the Query and list out .\n",
    "Top3_violation_code_df = spark.sql(sql_25)\n",
    "Top3_violation_code_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations***\n",
    ">- **The most common violation codes based on number of tickets received on Year 2017 are - `21`,`36` and `38` **<br>\n",
    ">- **The values below shows the parking violation codes in New York City and their fines.**<br>\n",
    ">    -  **Code `21`:  For Manhattan 96th St. & below - `$65`  ; All Other Areas:  `$45` ; Average - `$55.00`**\n",
    ">    -  **Code `36`:  For Manhattan 96th St. & below - `$50`  ; All Other Areas:  `$50` ; Average - `$50.00`**\n",
    ">    -  **Code `38`:  For Manhattan 96th St. & below - `$65`  ; All Other Areas:  `$35` ; Average - `$50.00`**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.2 Create a Data Frame with Violation Codes and Associated Fines (for High Density Locations & Others)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+-------------------+----------------+\n",
      "|Violation_Code|M96st_Fine_Per_Tkt|Others_Fine_Per_Tkt|Avg_Fine_Per_Tkt|\n",
      "+--------------+------------------+-------------------+----------------+\n",
      "|            21|              65.0|               45.0|            55.0|\n",
      "|            36|              50.0|               50.0|            50.0|\n",
      "|            38|              65.0|               35.0|            50.0|\n",
      "+--------------+------------------+-------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Create data frame for Fine Amounts and Average Amount\n",
    "\n",
    "# List to holds fine code and fine amounts.\n",
    "lst_code = [21,36,38]\n",
    "lst_m96_st = [65.0,50.0,65.0]\n",
    "lst_others = [45.0,50.0,35.0]\n",
    "\n",
    "# create a schema.\n",
    "from pyspark.sql.types import *\n",
    "myschema= StructType([ StructField(\"Violation_Code\", IntegerType(), True),\n",
    "                       StructField(\"M96st_Fine_Per_Tkt\", DoubleType(), True),\n",
    "                       StructField(\"Others_Fine_Per_Tkt\", DoubleType(), True),\n",
    "                     ])\n",
    "\n",
    "# Create a Top3 fine amount data frame.\n",
    "Top3_Fine_Amt_2017 = spark.createDataFrame(zip(lst_code,lst_m96_st,lst_others),schema = myschema)\n",
    "\n",
    "# Calculate the Average Amount\n",
    "Top3_Fine_Amt_2017 = Top3_Fine_Amt_2017.withColumn(\"Avg_Fine_Per_Tkt\", \\\n",
    "                    (Top3_Fine_Amt_2017['M96st_Fine_Per_Tkt'] +Top3_Fine_Amt_2017['Others_Fine_Per_Tkt'])/2.0)\n",
    "\n",
    "Top3_Fine_Amt_2017.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top3_violation_code_df.registerTempTable(\"tbl_violation\")\n",
    "Top3_Fine_Amt_2017.registerTempTable(\"tbl_fine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.2 Join the two Data Frames - 3 most common Violation Codes & Top 3 fine details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------------+\n",
      "|Violation_Code|Frequency_of_Tickets|Avg_Fine_Per_Tkt|\n",
      "+--------------+--------------------+----------------+\n",
      "|            21|              768087|            55.0|\n",
      "|            36|              662765|            50.0|\n",
      "|            38|              542079|            50.0|\n",
      "+--------------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_sql = \"SELECT tbl_violation.Violation_Code,\\\n",
    "                   tbl_violation.Frequency_of_Tickets,\\\n",
    "                   tbl_fine.Avg_Fine_Per_Tkt \\\n",
    "               FROM tbl_violation JOIN tbl_fine \\\n",
    "                    ON tbl_violation.Violation_Code == tbl_fine.Violation_Code\"\n",
    "\n",
    "#Execute the Query and list out .\n",
    "Top3_total_Amt_2017 = spark.sql(join_sql)\n",
    "Top3_total_Amt_2017.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------------+-------------------+\n",
      "|Violation_Code|Frequency_of_Tickets|Avg_Fine_Per_Tkt|Total_Fine_Amt_2017|\n",
      "+--------------+--------------------+----------------+-------------------+\n",
      "|            21|              768087|            55.0|        42244785.00|\n",
      "|            36|              662765|            50.0|        33138250.00|\n",
      "|            38|              542079|            50.0|        27103950.00|\n",
      "+--------------+--------------------+----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Total Amount create the new column.\n",
    "Top3_total_Amt_2017 = Top3_total_Amt_2017.withColumn(\"Total_Fine_Amt_2017\", \\\n",
    "                    (Top3_total_Amt_2017['Frequency_of_Tickets'] * Top3_total_Amt_2017['Avg_Fine_Per_Tkt'])\\\n",
    "                                                    .cast(DecimalType(18, 2)))\n",
    "                                                     \n",
    "Top3_total_Amt_2017.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage3: Q7: Answer : :\n",
    "> -  **The total occurrences of the three most common violation codes are ;**\n",
    "                    +--------------+--------------------+\n",
    "                    |Violation_Code|Frequency_of_Tickets|\n",
    "                    +--------------+--------------------+\n",
    "                    |            21|              768087|\n",
    "                    |            36|              662765|\n",
    "                    |            38|              542079|\n",
    "                    +--------------+--------------------+\n",
    " > - **The Top three violation code associated fines and their averages are as below ;**\n",
    "                     +--------------+------------------+-------------------+----------------+\n",
    "                    |Violation_Code|M96st_Fine_Per_Tkt|Others_Fine_Per_Tkt|Avg_Fine_Per_Tkt|\n",
    "                    +--------------+------------------+-------------------+----------------+\n",
    "                    |            21|              65.0|               45.0|            55.0|\n",
    "                    |            36|              50.0|               50.0|            50.0|\n",
    "                    |            38|              65.0|               35.0|            50.0|\n",
    "                    +--------------+------------------+-------------------+----------------+\n",
    " > - **The total amount collected for the three violation codes with the maximum tickets are;**\n",
    "                     +--------------+--------------------+----------------+-------------------+\n",
    "                    |Violation_Code|Frequency_of_Tickets|Avg_Fine_Per_Tkt|Total_Fine_Amt_2017|\n",
    "                    +--------------+--------------------+----------------+-------------------+\n",
    "                    |            21|              768087|            55.0|        42244785.00|\n",
    "                    |            36|              662765|            50.0|        33138250.00|\n",
    "                    |            38|              542079|            50.0|        27103950.00|\n",
    "                    +--------------+--------------------+----------------+-------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7: Question-7: What can you intuitively infer from these findings?\n",
    "> - The inference based on all above questions and finding are as below ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Answer : :\n",
    "###   The inference based on all above questions and finding are as below ;\n",
    "\n",
    "##### A. Examine the data\n",
    ">  ** 1. The number of parking tickets issued during year 2017 is approximately `5,431,918 Million Tickets`. (i.e, `5.4 Million Tickets`).**\n",
    "\n",
    ">  ** 2. The \tnumber of unique states of the registered plate of cars receiving parking tickets in the year are 65. However, there are 16055 records with state code 99.This implies that there is several parking tickets issued to vehicle less with an unknown registration state. For the sake of case study, we considered these unknown state code as 'NY'. So, the maximum parking tickets received by vehicles having registered plates are `64` and the state is 'NY'. **<br><br>\n",
    "     \n",
    "###### B. Aggregation tasks<br>\n",
    "\n",
    "**1. The frequency of top 5 Violation Codes high during the year 2017 are for ;** \n",
    "- ** `21` - No parking where parking is not allowed by sign, street marking or traffic control device. ** \n",
    "- ** `36` - Exceeding the posted speed limit in or near a designated school zone. **<br>\n",
    "- ** `38` - Failing to show a receipt or tag in the windshield. Drivers get a 5-minute grace period past the expired time on parking meter receipts.**\n",
    "- ** `14` - Standing or parking where standing is not allowed by sign, street marking or; traffic control device.**<br>\n",
    "- ** `20` - No parking where parking is not allowed by sign, street marking or traffic control device.**<br><br>\n",
    "- **Therefore, the highest frequency of tickets through the years is issued for No-parking violations, Exceeding Speed limit near school zones and Failing to show tag in the windsheild.** <br>\n",
    "     \n",
    "**2. The `top 5 Vehicle Body Types issued with parking tickets in 2017` are ;**\n",
    "- ** `SUBN` - Vehicles that can be registered with the suburban body type include station wagons, sport utility vehicles, hearses and ambulances.**\n",
    "- ** `4DSD` - 4 door Sedans**\n",
    "- ** `VAN`  - Type of vehicle used for transporting goods or people.**\n",
    "- ** `DELV` - Delivery Truck**\n",
    "- ** `SDN`  - Civilian Sedan**<br><br>\n",
    "\n",
    "- ** The top 5 Vehicle Make having issued with parking tickets in 2017 are ;**<br>\n",
    "     - ** Ford, Toyota, Honda , Nissan and Cheverlet.**<br>\n",
    "     \n",
    "** 3.1. From the analysis of violation of Precinct against the number of parking tickets ;**<br>\n",
    "   - **it is clear the highest number of tickets were issued with Violation Precinct 0. Since 0 is unknown precinct it may be issued with faulty tickets. The Violation Precinct codes are `19,14 and 1`.**\n",
    " \n",
    "      \n",
    "** 3.2. From the analysis of Issues Precinct against the number of parking tickets ;**<br>  \n",
    "- ** Reveals the highest number of tickets are issued for code `0`. Again, there is no code as 0 , the validity of the tickets raised are questionable. Other top issue Precinct codes are `19,14 and 1` .**\n",
    "\n",
    "   \n",
    "**4. While  observing the Top-5 violation codes for which tickets were issued in each of the above 3 Issuing Precincts (19,14 and 1) and comparing the results with all other Issuing Precincts for the year 2017, the`violation codes 21 and 36 have exceptionally high count of tickets`.**\n",
    "\n",
    "\n",
    "**5.1. There are no NULL values in the data.**\n",
    "\n",
    "**5.2. The Violation Time has been transformed into a suitable timestamp format and Divide 24 hours into 6 equal discrete bins of time.**\n",
    "\n",
    "**5.3. While observing the Frequency of Top-3 Violation Codes in each Violation Time Bin it is clear\n",
    "that the majority of the Tickets are issued between `0800-1100 Hrs and 1200-1500 Hrs`. It is also important to note,the exceptionally high number of tickets for `Violation Code 21` This is expected as Code 21 stands for No- Parking Zone Tickets. Majority of the public might park inappropriately during the morning rush, issued between `0800-1100 Hrs`.**\n",
    "\n",
    "**5.4. The Top-3 Violation Codes for 2016 are;<br>**\n",
    "  - **21: No Parking Violation **\n",
    "  - **36: Exceeding speed limit near School Zone**\n",
    "  - **38: Failing to show a receipt or tag in the windshield**<br>\n",
    "  - **While looking at the distribution of Violation Code 21, there is noticeably a `significant peak between 0800-1100 Hrs and dips between 1600-2300 Hrs`. For `Violation Code 36` there are almost `equal peaks between 0800-1100 Hrs and 1200-1500 Hrs` this may be as a result of people rushing to drop and pickup children to and from school.**\n",
    "  \n",
    "**6. After dividing the Issue Month into number of seasons, for each season and for the year 2017, Spring and Winter account for the highest number of parking tickets.**<br>\n",
    "  \n",
    "**7.1. The Top three most Violation Codes are ;<br>**\n",
    " - ** 21: No Parking Violation,**\n",
    " - ** 36: Exceeding speed limit near School Zone,**\n",
    " - ** 38: Failing to show a receipt or tag in the windshield**\n",
    "\n",
    "**7.2. In the year  2017,`Violation Code 21` brought the `highest total fine amount $42,244,785.00 Millions(42.2 Millions`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark Session to come out cleanly.\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
